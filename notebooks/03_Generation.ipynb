{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SocialProphet Phase 3: Content Generation\n",
    "\n",
    "This notebook demonstrates the content generation pipeline:\n",
    "1. Load forecast results from Phase 2\n",
    "2. Extract actionable insights\n",
    "3. Generate content using LLM (Llama 3.1)\n",
    "4. Validate content quality with FIIT framework\n",
    "\n",
    "**Target: FIIT Score > 85%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"HF Token available: {'Yes' if os.getenv('HF_TOKEN') else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SocialProphet modules\n",
    "from src.insights.extractor import InsightExtractor\n",
    "from src.insights.prompt_builder import PromptBuilder\n",
    "from src.generation.llm_client import HuggingFaceClient\n",
    "from src.generation.content_gen import ContentGenerator\n",
    "from src.generation.fiit_validator import FIITValidator\n",
    "from src.utils.config import Config\n",
    "\n",
    "config = Config()\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data (historical)\n",
    "train_df = pd.read_csv(config.PROCESSED_DATA_DIR / 'train_data.csv')\n",
    "train_df['ds'] = pd.to_datetime(train_df['ds'])\n",
    "\n",
    "# Load test data (predictions period)\n",
    "test_df = pd.read_csv(config.PROCESSED_DATA_DIR / 'test_data.csv')\n",
    "test_df['ds'] = pd.to_datetime(test_df['ds'])\n",
    "\n",
    "print(f\"Historical data: {len(train_df)} days\")\n",
    "print(f\"Test period: {len(test_df)} days\")\n",
    "print(f\"Date range: {train_df['ds'].min()} to {test_df['ds'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ensemble results\n",
    "with open(config.PROCESSED_DATA_DIR / 'ensemble_results.json', 'r') as f:\n",
    "    ensemble_results = json.load(f)\n",
    "\n",
    "print(\"Ensemble Model Performance:\")\n",
    "print(f\"  MAPE: {ensemble_results['ensemble_metrics']['mape']:.2f}%\")\n",
    "print(f\"  RMSE: {ensemble_results['ensemble_metrics']['rmse']:,.0f}\")\n",
    "print(f\"  RÂ²: {ensemble_results['ensemble_metrics']['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions DataFrame (simulated from test data)\n",
    "predictions_df = test_df.copy()\n",
    "predictions_df['ensemble_pred'] = predictions_df['y']\n",
    "predictions_df['ensemble_pred_original'] = predictions_df['y_raw']\n",
    "\n",
    "print(f\"Predictions shape: {predictions_df.shape}\")\n",
    "print(f\"Predicted engagement range: {predictions_df['ensemble_pred_original'].min():,.0f} - {predictions_df['ensemble_pred_original'].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize InsightExtractor\n",
    "extractor = InsightExtractor()\n",
    "\n",
    "# Extract all insights\n",
    "insights = extractor.extract_all(\n",
    "    predictions_df=predictions_df,\n",
    "    historical_df=train_df,\n",
    "    forecast_horizon=len(predictions_df)\n",
    ")\n",
    "\n",
    "print(\"Insights extracted!\")\n",
    "print(f\"Keys: {list(insights.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display trend analysis\n",
    "print(\"=\" * 50)\n",
    "print(\"TREND ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "trend = insights['trend_analysis']\n",
    "print(f\"Direction: {trend['direction']}\")\n",
    "print(f\"Strength: {trend['strength']}\")\n",
    "print(f\"7-day momentum: {trend['momentum_7d']:.2f}%\")\n",
    "print(f\"Historical mean: {trend['historical_mean']:,.0f}\")\n",
    "print(f\"Predicted mean: {trend['predicted_mean']:,.0f}\")\n",
    "print(f\"Confidence: {trend['confidence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display temporal patterns\n",
    "print(\"=\" * 50)\n",
    "print(\"TEMPORAL PATTERNS\")\n",
    "print(\"=\" * 50)\n",
    "temporal = insights['temporal_patterns']\n",
    "\n",
    "print(\"\\nBest Days:\")\n",
    "for day in temporal['best_days']:\n",
    "    print(f\"  {day['day']}: {day['avg_engagement']:,.0f} avg engagement\")\n",
    "\n",
    "ww = temporal['weekend_vs_weekday']\n",
    "print(f\"\\nWeekend vs Weekday:\")\n",
    "print(f\"  {ww['better'].capitalize()}s perform {ww['difference_pct']:.1f}% better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display recommendations\n",
    "print(\"=\" * 50)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 50)\n",
    "recs = insights['recommendations']\n",
    "\n",
    "print(\"\\nPosting Schedule:\")\n",
    "for rec in recs['posting_schedule']:\n",
    "    print(f\"  [{rec['priority'].upper()}] {rec['recommendation']}\")\n",
    "\n",
    "print(\"\\nContent Strategy:\")\n",
    "for rec in recs['content_strategy']:\n",
    "    print(f\"  [{rec['priority'].upper()}] {rec['recommendation']}\")\n",
    "\n",
    "targets = recs['engagement_targets']\n",
    "print(f\"\\nEngagement Targets:\")\n",
    "print(f\"  Minimum: {targets['minimum']:,.0f}\")\n",
    "print(f\"  Target: {targets['target']:,.0f}\")\n",
    "print(f\"  Stretch: {targets['stretch']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prompt context\n",
    "context = extractor.to_prompt_context()\n",
    "print(\"=\" * 50)\n",
    "print(\"PROMPT CONTEXT\")\n",
    "print(\"=\" * 50)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save insights\n",
    "insights_path = extractor.save_insights()\n",
    "print(f\"Insights saved to: {insights_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize LLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HuggingFace client\n",
    "try:\n",
    "    llm_client = HuggingFaceClient(model='llama')\n",
    "    print(\"LLM client initialized!\")\n",
    "    \n",
    "    # Check model status\n",
    "    status = llm_client.check_model_status()\n",
    "    print(f\"Model: {status.get('model', 'unknown')}\")\n",
    "    print(f\"Available: {status.get('available', False)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing LLM: {e}\")\n",
    "    print(\"Using mock responses for demonstration...\")\n",
    "    llm_client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PromptBuilder\n",
    "prompt_builder = PromptBuilder(\n",
    "    platform='instagram',\n",
    "    brand_voice='friendly, engaging, and informative'\n",
    ")\n",
    "\n",
    "# Get system prompt\n",
    "system_prompt = prompt_builder.get_system_prompt()\n",
    "print(\"System Prompt:\")\n",
    "print(\"-\" * 50)\n",
    "print(system_prompt[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build post prompt\n",
    "post_prompt = prompt_builder.build_post_prompt(\n",
    "    insights=insights,\n",
    "    theme='educational',\n",
    "    topic='social media engagement tips'\n",
    ")\n",
    "\n",
    "print(\"Post Generation Prompt:\")\n",
    "print(\"-\" * 50)\n",
    "print(post_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ContentGenerator\n",
    "if llm_client:\n",
    "    generator = ContentGenerator(llm_client, prompt_builder)\n",
    "    \n",
    "    # Generate a single post\n",
    "    print(\"Generating post...\")\n",
    "    post = generator.generate_post(\n",
    "        insights=insights,\n",
    "        theme='educational',\n",
    "        topic='boosting engagement'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"GENERATED POST\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nCaption:\\n{post.get('caption', 'N/A')}\")\n",
    "    print(f\"\\nHashtags: {' '.join(post.get('hashtags', []))}\")\n",
    "    print(f\"\\nBest Time: {post.get('best_time', 'N/A')}\")\n",
    "    print(f\"Content Type: {post.get('content_type', 'N/A')}\")\n",
    "else:\n",
    "    # Demo content\n",
    "    post = {\n",
    "        'caption': 'Ready to boost your engagement? Here are 3 proven tips that increased our reach by 50%! What strategies work best for you? Drop a comment below!',\n",
    "        'hashtags': ['#socialmediatips', '#engagement', '#growthhacks', '#marketing', '#contentcreator'],\n",
    "        'best_time': 'Tuesday 10:00 AM',\n",
    "        'content_type': 'carousel'\n",
    "    }\n",
    "    print(\"Using demo content (LLM not available)\")\n",
    "    print(f\"\\nCaption: {post['caption']}\")\n",
    "    print(f\"Hashtags: {' '.join(post['hashtags'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate with FIIT Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FIIT Validator\n",
    "validator = FIITValidator()\n",
    "\n",
    "# Get content to validate\n",
    "content_to_validate = post.get('caption', '')\n",
    "if post.get('hashtags'):\n",
    "    content_to_validate += ' ' + ' '.join(post['hashtags'])\n",
    "\n",
    "print(f\"Content to validate ({len(content_to_validate)} chars):\")\n",
    "print(content_to_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate content\n",
    "validation_result = validator.validate(\n",
    "    content=content_to_validate,\n",
    "    insights=insights,\n",
    "    target_tone='engaging'\n",
    ")\n",
    "\n",
    "# Print score report\n",
    "report = validator.get_score_report(validation_result)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed breakdown\n",
    "scores = validation_result['scores']\n",
    "details = validation_result['details']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DETAILED BREAKDOWN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nFLUENCY:\")\n",
    "print(f\"  Score: {scores['fluency']:.2f}\")\n",
    "print(f\"  Word count: {details['fluency'].get('word_count', 'N/A')}\")\n",
    "print(f\"  Flesch Reading Ease: {details['fluency'].get('flesch_reading_ease', 'N/A')}\")\n",
    "\n",
    "print(\"\\nINTERACTIVITY:\")\n",
    "print(f\"  Score: {scores['interactivity']:.2f}\")\n",
    "print(f\"  Has CTA: {details['interactivity'].get('has_cta', False)}\")\n",
    "print(f\"  Has Question: {details['interactivity'].get('has_question', False)}\")\n",
    "print(f\"  Emoji count: {details['interactivity'].get('emoji_count', 0)}\")\n",
    "print(f\"  Hashtag count: {details['interactivity'].get('hashtag_count', 0)}\")\n",
    "\n",
    "print(\"\\nINFORMATION:\")\n",
    "print(f\"  Score: {scores['information']:.2f}\")\n",
    "print(f\"  Has Numbers: {details['information'].get('has_numbers', False)}\")\n",
    "print(f\"  Has Value Indicators: {details['information'].get('has_value_indicators', False)}\")\n",
    "\n",
    "print(\"\\nTONE:\")\n",
    "print(f\"  Score: {scores['tone']:.2f}\")\n",
    "print(f\"  Detected Tone: {details['tone'].get('detected_tone', 'N/A')}\")\n",
    "print(f\"  Sentiment Polarity: {details['tone'].get('sentiment_polarity', 0):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if target met\n",
    "overall_score = scores['overall']\n",
    "target = validator.TARGET_OVERALL\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nOverall FIIT Score: {overall_score:.2f}\")\n",
    "print(f\"Target Score: {target}\")\n",
    "print(f\"Status: {'PASS' if overall_score >= target else 'NEEDS IMPROVEMENT'}\")\n",
    "\n",
    "if validation_result['improvements_needed']:\n",
    "    print(\"\\nImprovements Needed:\")\n",
    "    for imp in validation_result['improvements_needed']:\n",
    "        print(f\"  - {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Multiple Posts (Campaign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple posts with different themes\n",
    "themes = ['educational', 'inspirational', 'behind-the-scenes', 'promotional', 'interactive']\n",
    "\n",
    "all_posts = []\n",
    "all_scores = []\n",
    "\n",
    "for theme in themes:\n",
    "    if llm_client:\n",
    "        post = generator.generate_post(insights, theme=theme)\n",
    "    else:\n",
    "        # Demo posts for each theme\n",
    "        demo_posts = {\n",
    "            'educational': 'Did you know? Posting on Tuesdays can boost engagement by 20%! Here are the best practices we discovered.',\n",
    "            'inspirational': 'Every great brand started with a single post. Keep creating, keep growing!',\n",
    "            'behind-the-scenes': 'A sneak peek at how we create content! What goes into your posts?',\n",
    "            'promotional': 'Limited time offer! Check out our latest features designed to boost your engagement.',\n",
    "            'interactive': 'Quick poll: What type of content do you prefer? A) Tips B) Stories C) Tutorials. Comment below!'\n",
    "        }\n",
    "        post = {'caption': demo_posts[theme], 'hashtags': ['#demo', '#content'], 'theme': theme}\n",
    "    \n",
    "    content = post.get('caption', '') + ' ' + ' '.join(post.get('hashtags', []))\n",
    "    result = validator.validate(content, insights)\n",
    "    \n",
    "    all_posts.append(post)\n",
    "    all_scores.append({\n",
    "        'theme': theme,\n",
    "        'overall': result['scores']['overall'],\n",
    "        'fluency': result['scores']['fluency'],\n",
    "        'interactivity': result['scores']['interactivity'],\n",
    "        'information': result['scores']['information'],\n",
    "        'tone': result['scores']['tone'],\n",
    "        'passed': result['all_passed']\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "scores_df = pd.DataFrame(all_scores)\n",
    "print(\"\\nCampaign FIIT Scores:\")\n",
    "print(scores_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average scores\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CAMPAIGN SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTotal Posts: {len(all_posts)}\")\n",
    "print(f\"Average FIIT Score: {scores_df['overall'].mean():.2f}\")\n",
    "print(f\"Posts Passing (>0.85): {scores_df['passed'].sum()}/{len(scores_df)}\")\n",
    "print(f\"\\nBest Theme: {scores_df.loc[scores_df['overall'].idxmax(), 'theme']} ({scores_df['overall'].max():.2f})\")\n",
    "print(f\"Worst Theme: {scores_df.loc[scores_df['overall'].idxmin(), 'theme']} ({scores_df['overall'].min():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile final results\n",
    "generation_results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'platform': 'instagram',\n",
    "    'insights_summary': {\n",
    "        'trend': insights['trend_analysis']['direction'],\n",
    "        'best_days': [d['day'] for d in insights['temporal_patterns']['best_days']],\n",
    "        'predicted_engagement': insights['predictions_summary']['mean_predicted']\n",
    "    },\n",
    "    'posts_generated': len(all_posts),\n",
    "    'average_fiit_score': float(scores_df['overall'].mean()),\n",
    "    'posts_passing': int(scores_df['passed'].sum()),\n",
    "    'target_fiit': 0.85,\n",
    "    'score_breakdown': {\n",
    "        'fluency_avg': float(scores_df['fluency'].mean()),\n",
    "        'interactivity_avg': float(scores_df['interactivity'].mean()),\n",
    "        'information_avg': float(scores_df['information'].mean()),\n",
    "        'tone_avg': float(scores_df['tone'].mean())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results\n",
    "results_path = config.PROCESSED_DATA_DIR / 'generation_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(generation_results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 3 CONTENT GENERATION - FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nPlatform: Instagram\")\n",
    "print(f\"Posts Generated: {len(all_posts)}\")\n",
    "print(f\"\\nFIIT Scores:\")\n",
    "print(f\"  Fluency:        {scores_df['fluency'].mean():.2f}\")\n",
    "print(f\"  Interactivity:  {scores_df['interactivity'].mean():.2f}\")\n",
    "print(f\"  Information:    {scores_df['information'].mean():.2f}\")\n",
    "print(f\"  Tone:           {scores_df['tone'].mean():.2f}\")\n",
    "print(f\"  \" + \"-\" * 30)\n",
    "print(f\"  OVERALL:        {scores_df['overall'].mean():.2f}\")\n",
    "print(f\"\\nTarget: 0.85\")\n",
    "print(f\"Status: {'TARGET MET' if scores_df['overall'].mean() >= 0.85 else 'NEEDS IMPROVEMENT'}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
