{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SocialProphet - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs initial exploration of social media engagement data.\n",
    "\n",
    "## Contents\n",
    "1. Data Loading\n",
    "2. Basic Statistics\n",
    "3. Temporal Analysis\n",
    "4. Engagement Distribution\n",
    "5. Correlation Analysis\n",
    "6. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Import project modules\n",
    "from src.data_processing.collector import DataCollector\n",
    "from src.data_processing.preprocessor import DataPreprocessor\n",
    "from src.data_processing.features import FeatureEngineer\n",
    "from src.utils.config import Config\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize collector\n",
    "collector = DataCollector()\n",
    "\n",
    "# Load your dataset - update the path as needed\n",
    "# Option 1: Load from CSV\n",
    "# df = collector.load_csv('../data/raw/social_media_data.csv')\n",
    "\n",
    "# Option 2: Load Kaggle dataset (uncomment to use)\n",
    "# df = collector.load_kaggle_dataset('subashmaster0411/social-media-engagement-dataset')\n",
    "\n",
    "# For demo, create sample data\n",
    "print(\"Please load your dataset by uncommenting the appropriate line above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data overview\n",
    "# Uncomment after loading data\n",
    "# print(f\"Dataset Shape: {df.shape}\")\n",
    "# print(f\"\\nColumns: {list(df.columns)}\")\n",
    "# print(f\"\\nData Types:\\n{df.dtypes}\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical summary\n",
    "# Uncomment after loading data\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "# Uncomment after loading data\n",
    "# missing = df.isnull().sum()\n",
    "# missing_pct = (missing / len(df)) * 100\n",
    "# pd.DataFrame({'Missing': missing, 'Percentage': missing_pct}).sort_values('Missing', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp and analyze date range\n",
    "# Uncomment after loading data\n",
    "# df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "# print(f\"Date Range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "# print(f\"Total Days: {(df['timestamp'].max() - df['timestamp'].min()).days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement over time plot\n",
    "def plot_engagement_over_time(df, date_col='timestamp', value_col='engagement'):\n",
    "    \"\"\"Plot engagement trend over time.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Daily aggregation\n",
    "    daily = df.set_index(date_col)[value_col].resample('D').mean()\n",
    "    \n",
    "    ax.plot(daily.index, daily.values, linewidth=2, label='Daily Average')\n",
    "    \n",
    "    # Add rolling average\n",
    "    rolling = daily.rolling(window=7).mean()\n",
    "    ax.plot(rolling.index, rolling.values, linewidth=2, linestyle='--', label='7-day Moving Avg')\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Engagement', fontsize=12)\n",
    "    ax.set_title('Engagement Over Time', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Uncomment to use:\n",
    "# plot_engagement_over_time(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly engagement pattern\n",
    "def plot_hourly_pattern(df, date_col='timestamp', value_col='engagement'):\n",
    "    \"\"\"Plot engagement by hour of day.\"\"\"\n",
    "    df['hour'] = df[date_col].dt.hour\n",
    "    hourly = df.groupby('hour')[value_col].mean()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(hourly.index, hourly.values, color='steelblue')\n",
    "    ax.set_xlabel('Hour of Day', fontsize=12)\n",
    "    ax.set_ylabel('Average Engagement', fontsize=12)\n",
    "    ax.set_title('Engagement by Hour of Day', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(range(24))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Uncomment to use:\n",
    "# plot_hourly_pattern(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of week pattern\n",
    "def plot_weekly_pattern(df, date_col='timestamp', value_col='engagement'):\n",
    "    \"\"\"Plot engagement by day of week.\"\"\"\n",
    "    df['day_of_week'] = df[date_col].dt.dayofweek\n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    daily = df.groupby('day_of_week')[value_col].mean()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(range(7), daily.values, color='coral')\n",
    "    ax.set_xlabel('Day of Week', fontsize=12)\n",
    "    ax.set_ylabel('Average Engagement', fontsize=12)\n",
    "    ax.set_title('Engagement by Day of Week', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(range(7))\n",
    "    ax.set_xticklabels(days)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Uncomment to use:\n",
    "# plot_weekly_pattern(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Engagement Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of engagement metrics\n",
    "def plot_engagement_distribution(df, columns=['likes', 'comments', 'shares']):\n",
    "    \"\"\"Plot distribution of engagement metrics.\"\"\"\n",
    "    available_cols = [c for c in columns if c in df.columns]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(available_cols), figsize=(15, 5))\n",
    "    if len(available_cols) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, col in zip(axes, available_cols):\n",
    "        ax.hist(df[col], bins=50, edgecolor='black', alpha=0.7)\n",
    "        ax.set_xlabel(col.capitalize(), fontsize=12)\n",
    "        ax.set_ylabel('Frequency', fontsize=12)\n",
    "        ax.set_title(f'Distribution of {col.capitalize()}', fontsize=12)\n",
    "        ax.axvline(df[col].mean(), color='red', linestyle='--', label=f'Mean: {df[col].mean():.1f}')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Uncomment to use:\n",
    "# plot_engagement_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "def plot_boxplots(df, columns=['likes', 'comments', 'shares']):\n",
    "    \"\"\"Plot box plots for outlier detection.\"\"\"\n",
    "    available_cols = [c for c in columns if c in df.columns]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    df[available_cols].boxplot(ax=ax)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_title('Engagement Metrics - Outlier Detection', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Uncomment to use:\n",
    "# plot_boxplots(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"Plot correlation matrix for numeric columns.\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, ax=ax, square=True)\n",
    "    ax.set_title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Uncomment to use:\n",
    "# plot_correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data validation\n",
    "# preprocessor = DataPreprocessor()\n",
    "# validation = preprocessor.validate_data(df)\n",
    "# print(\"Data Validation Results:\")\n",
    "# print(f\"Is Valid: {validation['is_valid']}\")\n",
    "# print(f\"Issues: {validation['issues']}\")\n",
    "# print(f\"Stats: {validation['stats']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview feature engineering\n",
    "# feature_engineer = FeatureEngineer()\n",
    "# df_features = feature_engineer.create_all_features(df)\n",
    "# print(f\"Original columns: {len(df.columns)}\")\n",
    "# print(f\"After feature engineering: {len(df_features.columns)}\")\n",
    "# df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and save data\n",
    "# preprocessor = DataPreprocessor()\n",
    "# df_clean = preprocessor.clean_data(df)\n",
    "# df_clean = preprocessor.handle_missing_values(df_clean)\n",
    "# collector.save_data(df_clean, 'cleaned_data.csv', data_type='processed')\n",
    "# print(\"Data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This EDA notebook provides:\n",
    "- Data loading and basic inspection\n",
    "- Temporal pattern analysis\n",
    "- Engagement distribution visualization\n",
    "- Correlation analysis\n",
    "- Data quality validation\n",
    "\n",
    "**Next Steps:**\n",
    "1. Load your actual dataset\n",
    "2. Run all analysis cells\n",
    "3. Save processed data\n",
    "4. Proceed to forecasting (02_Forecasting.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
